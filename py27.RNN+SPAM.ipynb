{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'label', u'sms'], dtype='object')\n",
      "(5572, 2)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('sms2.tsv', sep='\\t')\n",
    "print(df.columns)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of claases: 2\n",
      "['ham', 'spam']\n",
      "{'ham': 0, 'spam': 1}\n"
     ]
    }
   ],
   "source": [
    "# 클래스 파악\n",
    "classes=sorted(set(df['label']))\n",
    "class_to_idx={}\n",
    "\n",
    "# 모든 클래스에 대해\n",
    "for i, c in enumerate(classes):\n",
    "    class_to_idx.update({c:i})\n",
    "    \n",
    "nclass=len(classes)\n",
    "\n",
    "print(\"# of claases: %d\" %nclass)\n",
    "print(classes)\n",
    "print(class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label, sms만 남기기\n",
    "# 최대 텍스트 길이만큼 자르기\n",
    "new_df=pd.DataFrame({'label': df['label'],\n",
    "                    'sms': df['sms'].str.slice(start=0, stop=max_length)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 중복 제거\n",
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.DataFrame(new_df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5169"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I wont get concentration dear you know you are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Only just got this message, not ignoring you. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>WIN a year supply of CDs 4 a store of ur choic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! Your Mobile number has been awarded wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>It should take about  &amp;lt;#&amp;gt;  min</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  I wont get concentration dear you know you are...\n",
       "1   ham  Only just got this message, not ignoring you. ...\n",
       "2  spam  WIN a year supply of CDs 4 a store of ur choic...\n",
       "3  spam  URGENT! Your Mobile number has been awarded wi...\n",
       "4   ham               It should take about  &lt;#&gt;  min"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle\n",
    "df_shuffled=new_df.sample(frac=1).reset_index(drop=True)\n",
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index for train: 0~4652\n",
      "index for test: 4652~5168\n"
     ]
    }
   ],
   "source": [
    "# train, test split\n",
    "train_ratio=0.9\n",
    "\n",
    "s, e= 0, int(df_shuffled.shape[0] * train_ratio)\n",
    "df_train=pd.DataFrame({'label': df_shuffled['label'][s:e],\n",
    "                      'sms':df_shuffled['sms'][s:e]})\n",
    "print(\"index for train: %d~%d\" %(s,e))\n",
    "\n",
    "s, e = e, e+int(df_shuffled.shape[0] * (1.0-train_ratio))\n",
    "print(\"index for test: %d~%d\" %(s,e))\n",
    "df_test=pd.DataFrame({'label': df_shuffled['label'][s:e],\n",
    "                     'sms': df_shuffled['sms'][s:e]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4652, 2)\n",
      "(516, 2)\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4652, 2)\n",
      "(516, 2)\n"
     ]
    }
   ],
   "source": [
    "# ↑이렇게 해도되지않았을까\n",
    "train_ratio=0.9\n",
    "index=int(df_shuffled.shape[0] * train_ratio)\n",
    "\n",
    "df_train_=df_shuffled[0:index]\n",
    "df_test_=df_shuffled[index:-1]\n",
    "\n",
    "print(df_train_.shape)\n",
    "print(df_test_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장\n",
    "df_train.to_csv('./sms.maxlen.uniq.shuf.train.tsv',\n",
    "               header=False, index=False, sep='\\t')\n",
    "df_test.to_csv('./sms.maxlen.uniq.shuf.test.tsv',\n",
    "               header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 will reach the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 won't be maintained after that date. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Collecting torchtext==0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/80/1cde2a940fe42d5572487e47533f4b08302a0dd2c64bbd04116731cd7109/torchtext-0.4.0.tar.gz (45kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 18.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from torchtext==0.4.0) (4.36.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from torchtext==0.4.0) (2.22.0)\n",
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from torchtext==0.4.0) (1.4.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from torchtext==0.4.0) (1.16.5)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from torchtext==0.4.0) (1.12.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from requests->torchtext==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from requests->torchtext==0.4.0) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from requests->torchtext==0.4.0) (1.25.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages (from requests->torchtext==0.4.0) (2019.11.28)\n",
      "Building wheels for collected packages: torchtext\n",
      "  Building wheel for torchtext (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torchtext: filename=torchtext-0.4.0-cp27-none-any.whl size=52131 sha256=428313ab50756fd001218f991f2a8b3c424103cb3f4431829586251105bcfc6d\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/7f/0b/a7/53f554f01d205ac7039ef96028eb886f52e235cdfae5ecf7ef\n",
      "Successfully built torchtext\n",
      "Installing collected packages: torchtext\n",
      "Successfully installed torchtext-0.4.0\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data_loader.py 오픈소스 로드하기<br>\n",
    "조건확인\n",
    "- 두 개 필드로 이루어져있어야\n",
    "- tab으로 분리되어 있어야 <br>\n",
    "\n",
    "스펙\n",
    "- train, valid 파일로 나눌 것임\n",
    "- label, text 필두 두개 컬럼으로 이루어짐 <br>\n",
    "\n",
    "-> train용 loader, valid용 loader 만들것임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN + SMS 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02 하이퍼파라미터 셋팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "batch_size=128\n",
    "num_epochs=10\n",
    "\n",
    "word_vec_size=256\n",
    "dropout_p=0.3\n",
    "\n",
    "hidden_size=512\n",
    "num_layers=4\n",
    "\n",
    "learning_rate=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device configuration\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03 sms train, test dataset 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders=DataLoader(\n",
    "    train_fn='sms.maxlen.uniq.shuf.train.tsv',\n",
    "        batch_size=batch_size,\n",
    "        valid_ratio=.2, # 8:2\n",
    "        device=-1,\n",
    "        max_vocab=999999,\n",
    "        min_freq=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loaders=DataLoader(\n",
    "    train_fn='sms.maxlen.uniq.shuf.test.tsv',\n",
    "        batch_size=batch_size,\n",
    "        valid_ratio=.01, # 모두 train(0이 안되서 0.01로)\n",
    "        device=-1,\n",
    "        max_vocab=999999,\n",
    "        min_freq=5,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04 대략적인 데이터 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('|train| = ', 3722, '|valid| = ', 930)\n"
     ]
    }
   ],
   "source": [
    "print(\"|train| = \", len(loaders.train_loader.dataset),\n",
    "     '|valid| = ', len(loaders.valid_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('|vocab| = ', 1527, '|classes| = ', 2)\n"
     ]
    }
   ],
   "source": [
    "vocab_size=len(loaders.text.vocab)\n",
    "num_classes=len(loaders.label.vocab)\n",
    "\n",
    "print(\"|vocab| = \", vocab_size, '|classes| = ', num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05 데이터 로드함수 이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "('size of data loaded at once: ', 128)\n",
      "('label: ', array(1))\n",
      "('text: ', (30,))\n",
      "('label: ', array(1))\n",
      "('text: ', (30,))\n",
      "('label: ', array(0))\n",
      "('text: ', (30,))\n",
      "[1]\n",
      "('size of data loaded at once: ', 128)\n",
      "('label: ', array(0))\n",
      "('text: ', (24,))\n",
      "('label: ', array(0))\n",
      "('text: ', (24,))\n",
      "('label: ', array(0))\n",
      "('text: ', (24,))\n",
      "[2]\n",
      "('size of data loaded at once: ', 128)\n",
      "('label: ', array(0))\n",
      "('text: ', (15,))\n",
      "('label: ', array(0))\n",
      "('text: ', (15,))\n",
      "('label: ', array(0))\n",
      "('text: ', (15,))\n",
      "[3]\n",
      "('size of data loaded at once: ', 128)\n",
      "('label: ', array(0))\n",
      "('text: ', (8,))\n",
      "('label: ', array(0))\n",
      "('text: ', (8,))\n",
      "('label: ', array(0))\n",
      "('text: ', (8,))\n"
     ]
    }
   ],
   "source": [
    "n=3\n",
    "for i, data in enumerate(loaders.train_loader):\n",
    "    labels=data.label\n",
    "    texts=data.text\n",
    "    \n",
    "    if i>n:\n",
    "        break\n",
    "    print(\"[%d]\" %i)\n",
    "    print(\"size of data loaded at once: \", len(labels))\n",
    "    \n",
    "    # 출력\n",
    "    for j in range(n):\n",
    "        label=labels[j].numpy()\n",
    "        text=texts[j].numpy()\n",
    "        print(\"label: \", label)\n",
    "        print(\"text: \", text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06 모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn with many-to-one\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                input_size,\n",
    "                word_vec_size,\n",
    "                hidden_size,\n",
    "                n_classes,\n",
    "                num_layers=4,\n",
    "                dropout_p=0.3\n",
    "                ):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size=input_size\n",
    "        self.word_vec_size=word_vec_size\n",
    "        self.hidden_size=hidden_size\n",
    "        self.n_classes=n_classes\n",
    "        self.num_layers=num_layers\n",
    "        self.dropout_p=dropout_p\n",
    "        \n",
    "        # 입력 차원(vocab_size), 출력 차원(word_vec_size)\n",
    "        self.emb=nn.Embedding(input_size, word_vec_size) #부터\n",
    "        \n",
    "        self.lstm=nn.LSTM(input_size=word_vec_size,\n",
    "                         hidden_size=hidden_size,\n",
    "                         num_layers=num_layers,\n",
    "                         dropout=dropout_p,\n",
    "                         batch_first=True,\n",
    "                         bidirectional=True)\n",
    "        self.fc=nn.Linear(hidden_size*2, num_classes)\n",
    "        \n",
    "        self.activation=nn.LogSoftmax(dim=-1) # 마지막 차원에 softmax 씌워줌\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, length)\n",
    "        x=self.emb(x)\n",
    "        # x: (batch_size, length, word_vec_size)\n",
    "        x, _ = self.lstm(x)\n",
    "        \n",
    "        # x: (bacth_Size, length, hidden_size*2)\n",
    "        # x[:-1]: (batch_size, 1, hidden_size*@)\n",
    "        out = self.activation(self.fc(x[:,-1]))\n",
    "        # self.fc(x[:-1]): (batch_Size, num_classes)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=RNN(input_size=vocab_size,\n",
    "         word_vec_size=word_vec_size,\n",
    "         hidden_size=hidden_size,\n",
    "         n_classes=num_classes,\n",
    "         num_layers=num_layers,\n",
    "         dropout_p=dropout_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeAccr(dloader, imodel):\n",
    "    correct=0\n",
    "    total=0\n",
    "    \n",
    "    model.eval()\n",
    "    for i, data in enumerate(dloader):\n",
    "        texts=data.text.to(device)\n",
    "        labels=data.label.to(device)\n",
    "        \n",
    "        output=model(texts)\n",
    "        _, output_index=torch.max(output,1)\n",
    "        \n",
    "        total +=labels.size(0)\n",
    "        correct += (output_index == labels).sum().float()\n",
    "        \n",
    "    model.train()\n",
    "    return (100*correct/total).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 87.74\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Test Data: %.2f\" %ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07 loss, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func=nn.NLLLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [10/30], Loss: 0.5536, Accr: 88.82\n",
      "Epoch [1/10], Step [20/30], Loss: 0.1615, Accr: 87.74\n",
      "Epoch [1/10], Step [30/30], Loss: 0.1280, Accr: 91.72\n",
      "Epoch [2/10], Step [10/30], Loss: 0.2028, Accr: 86.24\n",
      "Epoch [2/10], Step [20/30], Loss: 0.2587, Accr: 87.74\n",
      "Epoch [2/10], Step [30/30], Loss: 0.1699, Accr: 92.15\n",
      "Epoch [3/10], Step [10/30], Loss: 0.1019, Accr: 94.73\n",
      "Epoch [3/10], Step [20/30], Loss: 0.4707, Accr: 93.23\n",
      "Epoch [3/10], Step [30/30], Loss: 0.1358, Accr: 95.05\n",
      "Epoch [4/10], Step [10/30], Loss: 0.0218, Accr: 93.01\n",
      "Epoch [4/10], Step [20/30], Loss: 0.2102, Accr: 95.81\n",
      "Epoch [4/10], Step [30/30], Loss: 0.0125, Accr: 94.30\n",
      "Epoch [5/10], Step [10/30], Loss: 0.0800, Accr: 95.16\n",
      "Epoch [5/10], Step [20/30], Loss: 0.0015, Accr: 95.48\n",
      "Epoch [5/10], Step [30/30], Loss: 0.1426, Accr: 95.70\n",
      "Epoch [6/10], Step [10/30], Loss: 0.0015, Accr: 94.62\n",
      "Epoch [6/10], Step [20/30], Loss: 0.0021, Accr: 96.24\n",
      "Epoch [6/10], Step [30/30], Loss: 0.0022, Accr: 96.24\n",
      "Epoch [7/10], Step [10/30], Loss: 0.0038, Accr: 93.44\n",
      "Epoch [7/10], Step [20/30], Loss: 0.0357, Accr: 95.70\n",
      "Epoch [7/10], Step [30/30], Loss: 0.0170, Accr: 95.70\n",
      "Epoch [8/10], Step [10/30], Loss: 0.0005, Accr: 95.70\n",
      "Epoch [8/10], Step [20/30], Loss: 0.0366, Accr: 95.27\n",
      "Epoch [8/10], Step [30/30], Loss: 0.0584, Accr: 96.02\n",
      "Epoch [9/10], Step [10/30], Loss: 0.0532, Accr: 97.10\n",
      "Epoch [9/10], Step [20/30], Loss: 0.0370, Accr: 96.88\n",
      "Epoch [9/10], Step [30/30], Loss: 0.0111, Accr: 96.77\n",
      "Epoch [10/10], Step [10/30], Loss: 0.0008, Accr: 96.99\n",
      "Epoch [10/10], Step [20/30], Loss: 0.0140, Accr: 96.67\n",
      "Epoch [10/10], Step [30/30], Loss: 0.0008, Accr: 96.45\n"
     ]
    }
   ],
   "source": [
    "total_step=len(loaders.train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(loaders.train_loader):\n",
    "        texts=data.text.to(device)\n",
    "        labels=data.label.to(device)\n",
    "        \n",
    "#         print(\"[%d]\"%i)\n",
    "        \n",
    "        outputs=model(texts)\n",
    "        loss=loss_func(outputs,labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if(i+1)%10==0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accr: {:.2f}'\n",
    "                 .format(epoch+1, num_epochs, i+1, total_step,\n",
    "                        loss.item(),\n",
    "                        ComputeAccr(loaders.valid_loader, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 09 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Valid Data: 96.45\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Valid Data: %.2f\" %ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 학습된 파라미터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p27/lib/python2.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type RNN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "netname='./nets/rnn_weight_20201126.pkl'\n",
    "torch.save(model, netname, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11 학습된 파라미터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "netname='./nets/rnn_weight_20201126.pkl'\n",
    "model=torch.load(netname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Valid Data: 96.45\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Valid Data: %.2f\" %ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p27",
   "language": "python",
   "name": "conda_pytorch_p27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
